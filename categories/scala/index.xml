<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scala on open build/reports/life/index.html</title>
    <link>https://www.grimrose.org/blog/categories/scala/</link>
    <description>Recent content in Scala on open build/reports/life/index.html</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 17 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.grimrose.org/blog/categories/scala/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Introduction to Sangria</title>
      <link>https://www.grimrose.org/blog/2017/12/sangria-graphql/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2017/12/sangria-graphql/</guid>
      <description>はじめに この記事は、GraphQL Advent Calendar 2017の17日目の記事です。
Sangriaとは 概要 graphql.orgでも紹介されている通り、GraphQLのサーバーサイド実装です。
Sangriaは、幾つかのモジュールによって構成されていますが、おおよそ以下のような分類が可能です。
 コア JSONパーサー向けのライブラリ Relay用ライブラリ  JSONパーサーに関してなんでこんなにあるんだと他の言語の人は驚くかもしれませんが、 Scalaでは歴史的経緯により様々なJSONパーサーにまつわるライブラリが作られ、そして現在に至っています。
歴史的経緯については、eed3si9n_jaさんのスライドを参考にしてください。
  sbt, history of JSON libraries, microservices, and schema evolution (Tokyo ver)  from Eugene Yokota 
JSONパーサー自体もバックグラウンドで利用する関数型プログラミング向けのライブラリを選択できるようになっているため、バリエーションは様々です。 なので自分たちの好み、チーム事情に応じたライブラリを使うことが多いです。
初め方 2017-12-17時点でのリリースバージョンは、v1.3.3です。
http://sangria-graphql.org/getting-started/
Sangriaを使ってGraphQLを実装する手順は、以下のとおりです。
 Schemaの定義 Schemaのチェック Akka HTTPやPlayを使ってGraphQLのエンドポイントを用意すること  Define a GraphQL Schema Sangriaでは、Schemaの定義にmacroを用います。
とはいっても、ボイラープレートになりがちな箇所をSangriaがサポートするような形なので、そこまで複雑なことをやっているわけではありません。
Schema Execution Sangriaは、Schemaと、エンドポイントで受け取ったGraphQLのクエリを用いて、 Repository(Schemaにて取得の仕方を記載しておく)から目的に応じてExecutorが処理をします。 その際に、文字列からオブジェクトへ変換するInputUnmarshallerやオブジェクトからJSONへ変換するResultMarshallerを暗黙的に渡して、 必要なオブジェクトをJSONにして返すようにしてくれます。
GraphQLの操作(Query, Mutation, Subscription)に応じて、予めそれぞれSchemaに定義しておきます。
GraphQLのクエリは、QueryParserがASTへ変換します。 ここでは、Scalaのパーサコンビネータではなく、parboiledが使われています。
エンドポイントには、Akka HTTPとPlayを用いる方法が紹介されています。
 Akka-http GraphQL Endpoint Play GraphQL Endpoint  他のフレームワークでも、応用は出来ると思いますので、導入も簡単だと思います。</description>
    </item>
    
    <item>
      <title>Scala関西 Summit 2017へ参加してきました #scala_ks</title>
      <link>https://www.grimrose.org/blog/2017/09/scala-kansai-summit/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2017/09/scala-kansai-summit/</guid>
      <description>はじめに http://summit.scala-kansai.org/
https://skug.connpass.com/event/62304/
去年のScala関西 Summit 2016に参加してまた参加したいと思っていました。
そんな折CfPを受け付けていたので応募したところ受かったので、これまでやってきたことをまとめるいい機会でしたので、発表してきました。
Scala関西summit #scala_ks のCfP通ったー。初めて関西でしゃべるぞー。
&amp;mdash; とーます (@grimrose) 2017年7月9日 
Akka Streamsへ移行しとるんやけどちょっと聞いてや スライド
発表してきたのは、これまでのプロジェクトでやってきたことと、Akka Streamsをプロジェクトの途中から導入したことで何を考えたのかです。
幾つか質問を受けていて、その中で出てきたAlpakkaですが、まだakka-stream-alpakka-csvだけ導入していて、akka-stream-alpakka-s3を含めその他のモジュールについてはまだ検証中です。 モジュールによっても開発中だったりするので、ハマりどころもあります。
初期に導入したScalikeJDBC + SkinnyORMのデータ取り込み処理については、現在のところ他のバッチ処理の優先順位が高く、Akka Streamsの移行対象になってません。
今回紹介した制約ですが、既存の処理をどうやってAkka Streamsへ繋げるか、移行していくかという課題を元に考えたものなので、これを推奨しているわけではありません。
自分の発表の前にAkka Streamsのセッションが並んでいて、スタッフのタイムテーブルの組み方に助けていただいたと思っています。 おかげさまで説明や資料については、このセッションに来るくらいだから前のも来てるだろうという前提で作ることが出来ました。
Akka Streams 関連のセッション、打順が完璧すぎる……
&amp;mdash; にしかわささき (@nishikawasasaki) 2017年9月9日 
失敗したなと思ったのは、本番になると緊張して早口になってしまったのと、 それを緩和するために予めスライドにあと何分かを知れるのを仕込んでいたのにもかかわらず、上手く活用出来ず、予想よりも早く終わってしまったことでした。
セッション 今回参加したの以下のセッションです。
 ユーザーデータ基盤を１からScalaでつくった話し Scala and Akka apps on Kubernetes in ChatWork Scala の Functional Programming を支える技術 Scala on Docker(AWS ECS) グラフを知って理解するAkka Stream 「Scale with Scala」の道程 Scala on JVM をプロファイリングするツールの紹介 Property Based Testingでドメインロジックをテストする  今回一番印象的だったセッションは、ユーザデータ基盤についての話でした。 今関わっているプロジェクトの未来にも繋がる話だったり、周りを巻き込んでの検証をすすめていく方法など大変参考になりました。</description>
    </item>
    
    <item>
      <title>Scala Matsuri 2017に参加してきました #ScalaMatsuri</title>
      <link>https://www.grimrose.org/blog/2017/05/scala-matsuri/</link>
      <pubDate>Sun, 28 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2017/05/scala-matsuri/</guid>
      <description>はじめに ScalaMatsuri
今年もスタッフとして、参加してきました。
ブログを書こうとしてましたが、なかなか踏み出せていなかったのでScala将軍達の後の祭り2017のLTに応募して、 LT駆動でなんとか思い出しながら書いてみました。
担当 担当したのは以下の内容でした。
 Web周り 海外スピーカー向けのホテル予約 配信周りの調整  web周り Web周りは、上記のURLに表示するためのコンテンツをGithubで管理していて、スポンサーのロゴや原稿、タイムテーブル等、必要に応じて変更がPull Requestとして上がってくるので、パス等の確認をしてmergeボタンを押してました。
デプロイはtravis ciが、デプロイ先はGithub pagesなので、デプロイされたらslackに通知が来るので、違和感や位置ずれが無いか確認してました。
時々、typoなどを気づいてPull Requestをくださる方がいらっしゃってとても助かりました。
海外スピーカー向けのホテル予約 ホテルの団体予約とか普段の生活では全くやる機会がなかったのですが、前年の担当の方が資料を残してくださったお陰で手順や反省点を踏まえて始めました。
海外スピーカーに向けてのアナウンスや連絡については、翻訳チームと協力して行い、無事完了することが出来ました。
配信周りの調整 AbemaTV Developer Conference 2016に参加した祭に、Tech Conferenceでのカンファレンスの動画の配信について問い合わせを受け付けているとお話を伺っていたので、ScalaMatsuriの運営スタッフで話し合った結果、お願いすることになりました。
当日は、ネットワークの不調等も重なってしまい、お見苦しい点もあり申し訳ありませんでした。次回以降の反省点として共有しておきます。
当日 当日は、進行やタイムキーパーをやっていました。 スタッフをやっていると聞きたいセッションを聞けるというのはなかなか実現されないことが多いと思われがちですが、調整することが出来ます。 今回は進行とタイムキーパーのセッションが聞いてみたかったのに割り振られていて調整する手間が省けてよかったです。
おわりに ScalaMatsuriの初社員採用プロジェクト これまでの運営の失敗と成功の歴史 ~ScalaMatsuri 2017を振り返って~で紹介されている社員の方がいて下さったおかげで、 前回に比べて情報共有や交通整理がされるようになりました。
また、ScalaMatsuri2017（スタッフ）打ち上げの前に、振り返りの機会を設けて今回の反省点を共有して、次回に繋げることが出来ました。
遅くなってしまいましたが、ご参加いただいた皆さん、ご協賛いただいたスポンサーの皆さん、そして一緒に尽力してくださったスタッフの皆さん、本当にありがとうございました。</description>
    </item>
    
    <item>
      <title>JVMからSSHのポート転送でJDBC接続する</title>
      <link>https://www.grimrose.org/blog/2017/04/ssh-port-forward/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2017/04/ssh-port-forward/</guid>
      <description>はじめに 仕事上、windowsの端末からリモートのlinuxのDBにデータを送る必要があったのですが、 GUIでの手作業はしんどいので、簡単なツールを作ることにしました。
幸いなことにJVMが入っているので、JavaのSSHクライアントとJDBCを使ってやってみました。
検証 grimrose/ssh-port-forward-study
対象のサーバは、模擬的にDockerで作りました。
使用した言語は、慣れているgroovyと仕事で使ってるscala、ライブラリは、以下の通り。
 groovy  groovy-ssh groovy-sql  scala  dacr/jassh ScalikeJDBC   どちらのSSHクライアントもJSchをベースにしているのですが、Javaで書くよりだいぶ楽になっています。
SSHからリモートのコマンドやシェルスクリプトを動作させたり、実行結果の文字列やexit codeを受け取って更に次に繋げられるようになっていたり、 その他にもsftpやいろいろコマンドが用意されているみたいなので、デプロイツールとしてやミドルウェアの検証にも使えそうです。
おわりに windowsという制約はちょっとしたツールを作るだけでもホントにしんどいので、JVMがあってよかったと思ってます。
JVMやその他の言語でもランタイムをwindowsで動かせるようにしている人たちに感謝しつつ、日々の業務を楽にしていきたいと思います。</description>
    </item>
    
    <item>
      <title>ScalikeJDBCを使ってAmazon Athenaへアクセスしてみた</title>
      <link>https://www.grimrose.org/blog/2016/12/scala-advent-calendar-2016/</link>
      <pubDate>Sun, 11 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2016/12/scala-advent-calendar-2016/</guid>
      <description>はじめに この記事は、Scala Advent Calendar 2016の11日目のエントリです。
10日目 &amp;gt; ponkotuyさんのSkinnyORMのjoin定義についてです。
12日目 &amp;gt; aoiroaoinoさんのScala関西 Summit 2016 で Lens/Prism について発表してきたです。
ScalikeJDBCについて ScalikeJDBCは、SQLを使ってDBにアクセスしたい場合にとても使いやすいライブラリです。
Amazon Athenaについて AWS re:Invent 2016で発表された新しいサービスです。
詳細については、 Amazon Athena – Amazon S3上のデータに対話的にSQLクエリを や、AthenaのJDBCドライバを使ってS3のデータにSQL Workbench経由でアクセスする #reinvent #athena を見ていただければと思います。
S3に保存したデータに対してスキーマを定義してSQLでアクセスできるようになるのは、今後の自分の仕事にもつながってくるサービスでもあるので注目しています。
アクセスしてみた 検証したサンプルコードはこちらです。
grimrose/Scala-Advent-Calendar-2016
まずはじめに遭遇したのは、auto commitが常にONにするのが想定されているということでした。
遭遇した例外は、以下のような内容でした。
Exception encountered when invoking run on a nested suite - Failed to initialize pool: Disabling auto-commit mode not supported com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Disabling auto-commit mode not supported  仕方ないので、以下のようにして、auto commitをtrueへ変えました。</description>
    </item>
    
    <item>
      <title>GParsのActorでアクターモデルに入門する</title>
      <link>https://www.grimrose.org/blog/2016/12/gadvent-2016/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2016/12/gadvent-2016/</guid>
      <description>はじめに この記事は、G*Advent Calendar(Groovy,Grails,Gradle,Spock&amp;hellip;) Advent Calendar 2016の10日目のエントリです。
9日目 &amp;gt; nobeansさんのGrailsでUnix/Linux的実行可能WARファイルをつくるです。
11日目 &amp;gt; tyamaさんのGrailsでServer Sent Eventsを送信！(意訳版)です。
GParsとは GParsは、GroovyとJavaで利用できる並行・並列処理を利用しやすくなるライブラリです。
[Groovy]GParsで並列処理（基本＆コレクション編）を見ていただくと、 旧来のThreadや、java.util.concurrentをそのまま使うよりも並行処理が書きやすそうだと感じたのではないでしょうか。
GroovyがApacheに寄贈され、codehausが停止してしまったため、ソースコードやドキュメントがgithubに移管されています。
GPars/GPars
versionは、1.2.1のままです。
ですので、Gradleで利用する際は、以下のように依存を追加すれば利用できるようになります。
// https://mvnrepository.com/artifact/org.codehaus.gpars/gpars compile group: &#39;org.codehaus.gpars&#39;, name: &#39;gpars&#39;, version: &#39;1.2.1&#39;  Actorモデルについて アクターモデルについては、アクターモデルを見てください。
アクターモデルの実装されているもので代表的なものは、ErlangとAkkaが挙げられます。
この2つについては、もうエコシステムとも呼べるようなものになってしまっているので、アクターモデルだけを知ろうとすると、どこから手をつけていいのか分かりにくくなります。
そこで、GParsのActorを使ってアクターモデルの考え方を理解して行こうと思います。
GParsのActor GParsのActorのドキュメントを見ると、Actorの作り方はとてもシンプルです。
import groovyx.gpars.actor.Actor def actor = Actors.actor { loop { react { msg -&amp;gt; println &amp;quot;Received: $msg&amp;quot; } } } actor.send &#39;Hello, GPars!&#39; actor.join() // 停止するまで立ち上がったままにする。 // 止めるときはCtrl-C or プロセスを落とす  いわゆるPingPongをする場合はこんな感じです。</description>
    </item>
    
    <item>
      <title>Scala関西Summit 2016へ参加してきました #scala_ks</title>
      <link>https://www.grimrose.org/blog/2016/10/scalakansai2016/</link>
      <pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.grimrose.org/blog/2016/10/scalakansai2016/</guid>
      <description>はじめに http://summit.scala-kansai.org/
http://skug.connpass.com/event/38349/
去年のScala関西 Summit 2015に参加してまた参加したいと思っていたのと、 ScalaMatsuriの運営の参考になればと思い、参加しました。
セッション 今回は、どのセッションも面白そうだったのと、社内に持ち帰って共有したい内容が多かったので、悩みました。
その中で以下のセッションを選びました。
 はてなにおけるマイクロサービスとScala akka-stream を始めるときに覚えておきたいこと Implicit 再入門 Play2+SlickだけじゃないScalaのWeb/DBフレームワーク事情 Akka Clusterのネットワーク分断耐性設計 今からはじめる Lens/Prism scala.collection 再入門  Scalaを使いつつDDDを導入しているのでDDDと相性が良いことは実感していましたが、 一部とは言え、はてなのような大きなサービスのドメインを写し取りつつDDDを実践するという話は、とても参考になりました。 Scalaの定石を探る会は、とても興味深かったので今後のカンファレンス等で話される機会があるのを願ってます。
akka-streamは、Reactive Streamsについてずっと勉強していたので、実際にプロダクトに導入するにはどうすればいいのかを学びたかったので、 特に気になっていました。 小さな部品を組み合わせて大きな部品を作っていくところや、どのように既存のAkkaのActorと連携していくのかを知ることが出来てとても勉強になりました。
Implicit 再入門については、様々な入門書や日本語のドキュメントで知ってはいたものの、若干の不安がありましたが、がくぞー先生の説明で改めてScalaのImplicitの機能を知ることが出来ました。
Scalaのフレームワーク事情で紹介されていたScalikeJDBCは、現在のプロジェクトでも利用しており、 フレームワークの標準機能としてDAOやActiveRecordのような使い方が出来て、 さらにSQLの行数が多めの集計用クエリなどでもフレームワークを変えること無く利用出来るので、かなりおすすめです。 特に、ログ周りの設定は、クエリチューニングの際にとても助かっています。
Akka Clusterを導入するかは今後の状況次第ではありますが、分散処理という文脈の中でClusterでどういう故障が起きるのか、 故障が起きた際にどう対応すればいいのかを学ぶことが出来て、分散処理基盤を動かしていくことの難しさを知れました。
Monocle、Lens、Prismは名前だけ知っていて、コワイものだという印象でいましたが、 広く一般的なgetter/setterは関数の世界ではどういったものかを知れました。 case classのインスタンスのcopy hellは、ドメインオブジェクトの変換時にどうしても出てきてしまう問題の一つだと思うので、 適切な局面で扱えるようになりたいと思いました。
社内のScala勉強会でScalaのcollectionをどう使って行けばいいのか説明する時に参考に出来ると思いました。 特に計算量については、件数が多いデータを扱うことが多いプロジェクトなので、頭に入れながらやらないとパフォーマンスが出ないと思うので、ありがたい内容でした。
おわりに 丸一日ずっとScala漬けだったので途中疲れてしまいましたが、懇親会でTLで気になっていた人と実際にお会いする機会があったり、 お世話になっている人にお礼を伝えることが出来たりと、とても充実した一日でした。
また来年開催されることになったら、是非参加したいと思います。
参加者、スタッフ、スポンサーの皆様、ありがとうございました。</description>
    </item>
    
    <item>
      <title>ScalaMatsuri2016に参加してきました。 #ScalaMatsuri</title>
      <link>https://www.grimrose.org/blog/2016/02/scalamatsuri2016/</link>
      <pubDate>Mon, 08 Feb 2016 20:31:14 +0900</pubDate>
      
      <guid>https://www.grimrose.org/blog/2016/02/scalamatsuri2016/</guid>
      <description>ScalaMatsuri
はじまり 前回のScalaMatsuriが楽しかったので、スタッフとして参加してみようと思い飛び込んでみました。
https://japan-scala-association.doorkeeper.jp/events/23255
スタッフとして 約半年関わってみて、ここまで大きなカンファレンスの裏側をScalaのコミュニティの人たちと一緒に体験できたのは、正直楽しかったです。
終わってみて反省すべき点がたくさんありますが、これから開催されるであろう振り返りでいろいろ見直したいです。
開催当日の個人的な反省としては、日常会話の英語が出てこないというのはホントに辛かったです。
普段Webinarとかで聞いてたり、英語の文献とか読んでいたとしても話せるようにはならないことは分かっていたました。
ですが、短い時間でとっさにフレーズが出てこなくて慌てていて、相手にもその雰囲気が伝わるので申し訳ない気になって、さらにパニクるといった感じでした。
ジェスチャーや一緒に対応してくれていた人に助けてもらったり、最終的に英語が話せるスタッフの人にお願いしてなんとかしました。
おわりに まだ、残務がいろいろあって終わっていませんが、次回があるのならまたスタッフとして参加してみたいと思います。
ご参加いただいた皆さん、ご協賛いただいたスポンサーの皆さん、そして一緒に尽力してくださったスタッフの皆さん、本当にありがとうございました。</description>
    </item>
    
  </channel>
</rss>